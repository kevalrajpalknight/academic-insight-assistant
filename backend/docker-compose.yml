version: "3.8"

services:
  db:
    image: postgres:16-alpine
    container_name: postgres_db
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    restart: unless-stopped
    deploy: # Added deploy section for consistency and control
      resources:
        limits:
          memory: 512m # PostgreSQL can run with less for light usage, 512MB
          cpus: "0.5" # Half a CPU core

  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chromadb_server
    env_file:
      - .env
    volumes:
      - chromadb_data:/app/chroma
    ports:
      - "8000:8000" # ChromaDB's default port
    restart: unless-stopped
    deploy:
      resources:
        limits:
          # ChromaDB can be memory-intensive depending on vector count.
          # Starting very low due to your system's limitations.
          # Increase if you hit OOM errors or performance issues, but this will quickly hit your RAM limit.
          memory: 768m # 768MB, bare minimum for light ChromaDB usage
          cpus: "1" # One CPU core

  ollama:
    image: ollama/ollama
    container_name: ollama_server
    volumes:
      - ollama_models:/root/.ollama
    ports:
      - "11434:11434" # Ollama's default port
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 5G # Allocate 8 GB of memory
          cpus: "2" # Allocate 2 CPUs
    command: ["serve"] # Default command for Ollama to run as a server

volumes:
  postgres_data:
  chromadb_data:
  ollama_models:
